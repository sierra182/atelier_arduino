import openai
import json
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# üõ†Ô∏è Fonction que le LLM pourra appeler
def dire_bonjour(name):
    return f"Bonjour truc bidule {name} ! üòä"

def send_value(sensor: str, value: float):
    print(f"je vais envoyer ces infos a l'arduino: {sensor} : {value}")
    import serial
    import time

    # üß≠ Ouvre la connexion s√©rie
    ser = serial.Serial('/dev/ttyUSB0', 115200, timeout=1)
    time.sleep(2)  # ‚è≥ Attend que la connexion soit pr√™te

    # # ‚úâÔ∏è Envoie un message √† l'Arduino
    # ser.write(b'sensor-value')
    import json

    data = {
        "sensor": sensor,
        "value": value
    }

    # üîÑ Conversion en cha√Æne JSON
    json_str = json.dumps(data) + "\n"  # le \n permet √† l'Arduino de savoir quand le message se termine

    # üì§ Envoi via le port s√©rie
    ser.write(json_str.encode('utf-8'))
        # üì• Lit une r√©ponse (si l'Arduino en envoie)
    # line = ser.readline().decode('utf-8').strip()
    # print(f"Re√ßu depuis Arduino : {line}")

    # üîö Ferme la connexion
    ser.close()

# üì¶ D√©claration du tool (function)
function_tool = [
    {
        "name": "send_value",
        "description": "send the sensor type and the value to the arduino device",
        "parameters": {
            "type": "object",
            "properties": {
                "sensor": {
                    "type": "string",
                    "description": "type of the sensor"
                },
                 "value": {
                    "type": "number",
                    "description": "value of the sensor limit"
                }
            },
            "required": ["sensor", "value"]
        }
    }
]

# üß† Envoi d'un message √† GPT avec tool disponible
def infer(prompt: str):
    response = client.chat.completions.create(
        model="gpt-4o",  
        messages = [
        {
            "role": "system",
            "content": (
            "Tu es un assistant qui agit uniquement quand l'utilisateur fournit deux informations :\n"
            "1Ô∏è‚É£ le **type de capteur** ne peut etre que soit 'temperature' ou 'humidity', etc.)\n"
            "2Ô∏è‚É£ la **valeur seuil** (ex: 42)\n\n"
            "Ces deux √©l√©ments peuvent √™tre **explicites ou implicites dans la phrase**. "
            "Tu dois √™tre capable de les **interpr√©ter m√™me s‚Äôils sont sous-entendus** ¬ª.\n\n"
            "‚û°Ô∏è Si tu d√©tectes les deux, appelle la fonction correspondante.\n"
            "l'argument sensor pour la fonction, peux uniquement etre 'temp' ou 'hum'"
            "‚ùå Sinon, explique √† l'utilisateur que tu attends un type de capteur et une valeur seuil, sans essayer d'inventer ou de d√©vier."
        )
        },
        {
            "role": "user",
            "content": prompt
        }
    ],
        functions=function_tool,
        function_call="auto"
    )

    # üîç Si GPT d√©cide d'appeler une fonction...
    message = response.choices[0].message
    if message.function_call is not None:
        func_name = message.function_call.name
        args = json.loads(message.function_call.arguments)
        
        if func_name == "send_value":
            result = send_value(**args)
            # print("‚úÖ Appel r√©el de la fonction :", result)
    else:
        print("ü§ñ R√©ponse directe du LLM :", message.content)

def main():
    print("start")
    while True:
        try:
            prompt = input(">>> ")  # ‚å®Ô∏è Lecture depuis l'entr√©e standard
            infer(prompt)
        except BaseException:
            break

if __name__ == "__main__":
    main()